# Core Eval Configuration
# ========================
# This file defines the default configuration for RAG evaluation runs.
# Override individual settings via CLI arguments.

# Schema version
schema_version: "1.0"

# Execution settings
execution:
  workers: 5
  timeout_per_question_s: 120
  checkpoint_interval: 10

# Environment
environment:
  type: local                    # local | bfai-prod | bfai-staging
  orchestrator_url: null         # null = local import, or "https://api.bfai.com"

# Index configuration (loaded from jobs_config.json)
index:
  job_id: "bfai__eval66a_g1_1536_tt"
  # These are populated at runtime from jobs_config:
  # deployed_index_id, last_build, chunks_indexed, document_count,
  # embedding_model, embedding_dimension

# Generator model settings
generator:
  model: "gemini-2.5-flash"
  reasoning_effort: "low"        # low | medium | high
  temperature: 0.0
  max_output_tokens: 8192
  force_json: false              # Whether response_mime_type is application/json

# Judge model settings
judge:
  model: "gemini-2.0-flash"
  temperature: 0.0
  force_json: true               # Judge always uses JSON output

# Retrieval settings
retrieval:
  recall_k: 100
  precision_k: 25
  enable_hybrid: true
  rrf_ranking_alpha: 0.5
  enable_reranking: true
  ranking_model: "semantic-ranker-default@latest"

# Corpus configuration
corpus:
  file: "clients_qa_gold/BFAI/qa/QA_BFAI_gold_v1-0__q458.json"
  client: "BFAI"

# Pricing per 1M tokens (for cost calculation)
pricing:
  gemini-2.5-flash:
    input: 0.075
    output: 0.30
    thinking: 0.30
    cached: 0.01875
  gemini-3-flash-preview:
    input: 0.10
    output: 0.40
    thinking: 0.40
    cached: 0.025
  gemini-2.0-flash:
    input: 0.075
    output: 0.30
    thinking: 0.0
    cached: 0.01875

# Output settings
output:
  runs_dir: "runs"
  baselines_dir: "baselines"
  reports_dir: "reports/core_eval"
